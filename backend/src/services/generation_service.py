"""
Generation service for the Book RAG Chatbot
Handles response generation based on retrieved context
"""
from typing import List, Optional
from uuid import UUID
import openai
from ..models.query import Query
from ..models.retrieved_context import RetrievedContext
from ..models.response import GeneratedResponse
from ..models.citation import Citation
from ..config.settings import settings
from ..utils.helpers import generate_uuid


class GenerationService:
    def __init__(self):
        try:
            openai.api_key = settings.openai_api_key
            if not settings.openai_api_key or settings.openai_api_key.startswith("sk-..."):
                print("Warning: OpenAI API key not configured. Using mock responses.")
                self.mock_mode = True
            else:
                self.mock_mode = False
        except Exception as e:
            print(f"Warning: Could not configure OpenAI: {e}")
            self.mock_mode = True

    async def generate_response(
        self,
        query: Query,
        retrieved_contexts: List[RetrievedContext]
    ) -> GeneratedResponse:
        """
        Generate a response based on the query and retrieved contexts
        """
        if self.mock_mode:
            # Return a mock response when in mock mode
            mock_content = f"This is a mock response for your query: '{query.content}'. In a real implementation, this would be generated by the OpenAI API based on the retrieved context."

            # Create citations from the retrieved contexts
            citation_dicts = []
            for ctx in retrieved_contexts:
                citation_dict = {
                    "source_reference": ctx.source_citation,
                    "content_snippet": ctx.content[:200] + "..." if len(ctx.content) > 200 else ctx.content,
                    "document_id": str(ctx.document_id)
                }
                citation_dicts.append(citation_dict)

            # Create and return the generated response
            generated_response = GeneratedResponse(
                query_id=query.id,
                content=mock_content,
                citations=citation_dicts,
                status="GENERATED"
            )

            return generated_response

        # Prepare the context for the LLM
        context_text = "\n".join([ctx.content for ctx in retrieved_contexts])

        # Create the prompt for the LLM
        prompt = f"""
        You are a helpful assistant for a book about Physical AI and Humanoid Robotics.
        Answer the user's question based only on the provided context.
        If the context doesn't contain enough information to answer the question, say so.

        Context:
        {context_text}

        Question: {query.content}

        Answer:
        """

        try:
            # Call the OpenAI API to generate the response
            response = openai.ChatCompletion.create(
                model=settings.openai_model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant for a book about Physical AI and Humanoid Robotics. Answer questions based only on the provided context. Be concise but informative. Always cite your sources from the context."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )

            # Extract the generated content
            generated_content = response.choices[0].message['content'].strip()

            # Create citations from the retrieved contexts
            citation_dicts = []
            for ctx in retrieved_contexts:
                citation_dict = {
                    "source_reference": ctx.source_citation,
                    "content_snippet": ctx.content[:200] + "..." if len(ctx.content) > 200 else ctx.content,
                    "document_id": str(ctx.document_id)
                }
                citation_dicts.append(citation_dict)

            # Create and return the generated response
            generated_response = GeneratedResponse(
                query_id=query.id,
                content=generated_content,
                citations=citation_dicts,
                status="GENERATED"
            )

            return generated_response

        except Exception as e:
            # Handle any errors in generation
            error_response = GeneratedResponse(
                query_id=query.id,
                content=f"Sorry, I encountered an error processing your request: {str(e)}",
                citations=[],
                status="FAILED"
            )
            return error_response

    async def generate_followup_questions(
        self, 
        query: Query, 
        response: GeneratedResponse
    ) -> List[str]:
        """
        Generate potential follow-up questions based on the query and response
        """
        # Create a prompt for generating follow-up questions
        prompt = f"""
        Based on the following question and answer, suggest 3 potential follow-up questions:
        
        Question: {query.content}
        Answer: {response.content}
        
        Follow-up questions:
        1.
        2.
        3.
        """
        
        try:
            # Call the OpenAI API to generate follow-up questions
            response = openai.ChatCompletion.create(
                model=settings.openai_model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that suggests follow-up questions based on a question and answer pair."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.5
            )
            
            # Parse the response to extract follow-up questions
            content = response.choices[0].message['content'].strip()
            questions = [q.strip() for q in content.split('\n') if q.strip() and q.startswith(('1.', '2.', '3.'))]
            questions = [q.split('.', 1)[1].strip() for q in questions if '.' in q]
            
            return questions[:3]  # Return only the first 3 questions
            
        except Exception as e:
            print(f"Error generating follow-up questions: {e}")
            return []